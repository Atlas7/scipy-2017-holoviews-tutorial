{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href='bokeh.pydata.org'><img src=\"assets/bokeh_logo.svg\" alt=\"Bokeh logo\" width=\"4%;\" align=\"right\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href='http://www.holoviews.org'><img src=\"assets/header_logo.png\" alt=\"HoloViews logo\" width=\"20%;\" align=\"left\"/></a>\n",
    "<div style=\"float:right;\"><h2>07. Working with large datasets</h2></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HoloViews allows even high-dimensional datasets very easily however on its own standard data interfaces and plotting extensions can quickly reach their limits with very large datasets. When working with datasets of millions or even billions of datapoints HoloViews can flexibly extend to work with [``dask``](http://dask.pydata.org/en/latest/) dataframes which allows for out-of-core computation and parallel processing of large tabular datasets. Additionally HoloViews provides an interface for [``datashader``](http://datashader.readthedocs.io/en/latest/) allowing you to quickly visualize large datasets.\n",
    "\n",
    "The datashader library is designed to complement standard plotting libraries by providing visualizations for very large datasets, focusing on faithfully revealing the overall distribution, not just individual data points.\n",
    "\n",
    "Dask DataFrame is provides a functionally equivalent API to pandas but allows working with data out of core and scales out to many processors and even clusters. Here we will use it to load a large CSV files of taxi coordinates.\n",
    "\n",
    "<div >\n",
    "    <img align=\"left\" src=\"./assets/numba.png\" width='140px'></img>\n",
    "<img align=\"left\" src=\"./assets/dask.svg\" width='115px'></img>\n",
    "<img align=\"left\" src=\"./assets/datashader.png\" width='158px'></img>\n",
    "<img align=\"left\" src=\"./assets/holoviews.png\" width='140px'></img>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does datashader work?\n",
    "\n",
    "* Tools like Bokeh map Data directly into an HTML/JavaScript Plot\n",
    "* datashader renders Data into a screen-sized Aggregate array, from which an Image can be constructed then embedded into a Bokeh Plot\n",
    "* Only the fixed-sized Image needs to be sent to the browser, allowing millions or billions of datapoints to be used\n",
    "* Every step automatically adjusts to the data, but can be customized\n",
    "\n",
    "<img src=\"./assets/datashader_pipeline.png\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### When not to use datashader\n",
    "\n",
    "* Plotting less than 1e5 or 1e6 data points\n",
    "* When every datapoint matters; standard Bokeh will render all of them\n",
    "* For full interactivity (hover tools) with every datapoint\n",
    "\n",
    "#### When to use datashader\n",
    "\n",
    "* Actual big data; when Bokeh/Matplotlib have trouble\n",
    "* When the distribution matters more than individual points\n",
    "* When you find yourself sampling or binning to better understand the distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import holoviews as hv\n",
    "import dask.dataframe as dd\n",
    "import datashader as ds\n",
    "import geoviews as gv\n",
    "\n",
    "from holoviews.operation.datashader import datashade, aggregate\n",
    "from holoviews.plotting.util import fire\n",
    "datashade.cmap = fire\n",
    "hv.extension('bokeh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a first step we will load a large dataset using dask. If you have followed the setup instructions you will have downloaded a large CSV containing 12 million taxi trips, which will will load using dask, creating a dask dataframe that provides an API replicating pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ddf = dd.read_csv('../data/nyc_taxi.csv', parse_dates=['tpep_pickup_datetime'])\n",
    "ddf['hour'] = ddf.tpep_pickup_datetime.dt.hour\n",
    "\n",
    "# If your machine is low on RAM (<8GB) don't persist (everything will be much slower)\n",
    "ddf = ddf.persist()\n",
    "print('%s Rows' % len(ddf))\n",
    "print('Columns:', list(ddf.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In previous have already seen how to declare a set of [``Points``](http://holoviews.org/reference/elements/bokeh/Points.html) from a DataFrame, this works much the same, we pass in the DataFrame along with the key dimensions. Remember however we have 12 million rows of data, no plotting program will handle this well! Therefore we will use the ``datashader`` operation which will aggregate the data on a 2D grid and then apply shading, leaving us with an ``RGB`` Element to display:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%opts RGB [width=800 height=400]\n",
    "points = hv.Points(ddf, kdims=['dropoff_x', 'dropoff_y'])\n",
    "datashade(points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you zoom in you will have noted that the plot rerenders depending on the zoom level. This is because the datashade operation is a dynamic operation that also declares some linked streams. These are automatically instantiated and supply the ``x_range`` and ``y_range`` to the operation, which dynamically change as you zoom in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datashade.streams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Exercise: Plot the taxi pickup locations \n",
    "# Hint: The dataframe contains 'pickup_x' and 'pickup_y' columns\n",
    "# Optional: Change the cmap on the datashade operation to inferno\n",
    "\n",
    "from colorcet import inferno"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding a tile source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the GeoViews extension for HoloViews we can display a tile source in the background. Declare a bokeh WMTSTileSource and pass it to the gv.WMTS Element, then we can overlay it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%opts RGB [xaxis=None yaxis=None]\n",
    "import geoviews as gv\n",
    "from bokeh.models import WMTSTileSource\n",
    "url = 'https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{Z}/{Y}/{X}.jpg'\n",
    "wmts = WMTSTileSource(url=url)\n",
    "gv.WMTS(wmts) * datashade(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Exercise: Overlay the taxi pickup data on top of the Wikipedia tile source\n",
    "\n",
    "wiki_url = 'https://maps.wikimedia.org/osm-intl/{Z}/{X}/{Y}@2x.png'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregating with a variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we have simply been counting taxi dropoffs, but our dataset is much richer than that. We have information about a number of variables including the total cost of a taxi ride, the ``total_amount``. Datashader provides a number of ``aggregator`` functions, which you can supply to the datashade operation. Here use the ``ds.mean`` aggregator to compute the average cost of a trip at a dropoff location:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "selected = points.select(total_amount=(None, 1000))\n",
    "selected.data = selected.data.persist()\n",
    "gv.WMTS(wmts) * datashade(selected, aggregator=ds.mean('total_amount'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Exercise: Use the ds.min or ds.max aggregator to visualize tipping amounts by dropoff location\n",
    "# Hint: The tipping amounts are given by the ``tip_amount`` column\n",
    "# Optional: Eliminate outliers by using select"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping by a variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%opts Image [width=600 height=300 logz=True xaxis=None yaxis=None]\n",
    "taxi_ds = hv.Dataset(ddf)\n",
    "grouped = taxi_ds.to(hv.Points, ['dropoff_x', 'dropoff_y'], groupby=['hour'], dynamic=True)\n",
    "aggregate(grouped).redim.values(hour=range(24))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Exercise: Facet the trips in the morning hours as an NdLayout \n",
    "# Hint: You can reuse the grouped variable or select a subset before using the .to method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can overlay an invisible ``QuadMesh`` to reveal information on hover."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%opts QuadMesh [width=800 height=400 tools=['hover']] (alpha=0 hover_line_alpha=1 hover_fill_alpha=0)\n",
    "hover_info = aggregate(points, width=40, height=20, streams=[hv.streams.RangeXY]).map(hv.QuadMesh, hv.Image)\n",
    "gv.WMTS(wmts) * datashade(points) * hover_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read more:\n",
    "\n",
    "* Read the user guide on [Working with large data using datashader](http://holoviews.org/user_guide/Large_Data.html)\n",
    "* See a [bokeh app](http://holoviews.org/gallery/apps/bokeh/nytaxi_hover.html) using this dataset and an additional linked stream."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
